{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from math import floor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from EMNIST\n",
    "def loadEmnistFromNPY(filename):\n",
    "    try:\n",
    "        ret = np.load(filename)\n",
    "    except FileNotFoundError:\n",
    "        zipRef = zipfile.ZipFile('../data/EMNIST/balanced-data.zip')\n",
    "        zipRef.extractall('../data/EMNIST')\n",
    "        zipRef.close()\n",
    "        ret = np.load(filename)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use a small subset of the data rather than the entire dataset. This is done for performance reasons because SVM takes a very long time to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in EMNIST train data from .npy\n",
    "EMTrainData = loadEmnistFromNPY('../data/EMNIST/balanced-train-data.npy')\n",
    "EMTrainLabels = loadEmnistFromNPY('../data/EMNIST/balanced-train-labels.npy')\n",
    "\n",
    "# Read in EMNIST test data from .npy\n",
    "EMTestData = loadEmnistFromNPY('../data/EMNIST/balanced-test-data.npy')\n",
    "EMTestLabels = loadEmnistFromNPY('../data/EMNIST/balanced-test-labels.npy')\n",
    "\n",
    "# Downsample the data randomly\n",
    "percentTrainSample = .01\n",
    "percentTestSample = .1\n",
    "\n",
    "nrowsInTrainData = len(EMTrainData)\n",
    "nrowsInTestData = len(EMTestData)\n",
    "\n",
    "trainIndicies = np.random.choice(nrowsInTrainData, floor(percentTrainSample * nrowsInTrainData))\n",
    "testIndicies = np.random.choice(nrowsInTestData, floor(percentTestSample * nrowsInTestData))\n",
    "\n",
    "trainData = EMTrainData[trainIndicies]\n",
    "trainLabels = EMTrainLabels[trainIndicies]\n",
    "testData = EMTestData[testIndicies]\n",
    "testLabels = EMTestLabels[testIndicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the RBF kernel uses a distance metric in the calculation of its infinite dimensional projection of the data, the scaling of features is very important. \n",
    "$$exp(−\\gamma||x−x′||^2)$$\n",
    "If one feature varies from 1 to 1000, and another only varies between 1 and 2, the first feature can begin to dominate the calculation of the hyperplane. Although the data is inherently scaled from 1-255, this does not represent a true scaling of each feature (pixel). Some pixels only vary from 1-n where n is less than 255, and keeping it on the 255 scale makes this feature less significant. A min-max scaling is used to scale each feature from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():  # Silence a data conversion warning that is thrown from scaling.\n",
    "    warnings.simplefilter(\"ignore\")    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(trainData)\n",
    "    trainData = scaler.transform(trainData)\n",
    "    testData = scaler.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the model using cross-validation based on accuracy measure. Test a list of params for C and Gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.001}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.01}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.001, 'gamma': 0.1}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.001, 'gamma': 1}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.001, 'gamma': 10}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.001}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.01}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.01, 'gamma': 0.1}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.01, 'gamma': 1}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.01, 'gamma': 10}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
      "Accuracy: 0.038 for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1}\n",
      "Accuracy: 0.036 for {'kernel': 'rbf', 'C': 0.1, 'gamma': 10}\n",
      "Accuracy: 0.161 for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "Accuracy: 0.533 for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "Accuracy: 0.070 for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "Accuracy: 0.045 for {'kernel': 'rbf', 'C': 1, 'gamma': 1}\n",
      "Accuracy: 0.045 for {'kernel': 'rbf', 'C': 1, 'gamma': 10}\n",
      "Accuracy: 0.559 for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "Accuracy: 0.579 for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "Accuracy: 0.082 for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "Accuracy: 0.045 for {'kernel': 'rbf', 'C': 10, 'gamma': 1}\n",
      "Accuracy: 0.045 for {'kernel': 'rbf', 'C': 10, 'gamma': 10}\n"
     ]
    }
   ],
   "source": [
    "tuningParameters = [{'kernel': ['rbf'], \n",
    "                    'gamma': [.001, .01, .1, 1, 10],\n",
    "                     'C': [.001, .01, .1, 1, 10]}]\n",
    "test = GridSearchCV(svm.SVC(), tuningParameters, cv=3, scoring='accuracy')\n",
    "test.fit(trainData, trainLabels)\n",
    "\n",
    "means = test.cv_results_['mean_test_score']\n",
    "for mean, params in zip(means, test.cv_results_['params']):\n",
    "    print(\"Accuracy: %0.3f for %r\" % (mean, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest average cross validation accuracy was found to be 57.9% with gamma=.01 and C=10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
